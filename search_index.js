var documenterSearchIndex = {"docs":
[{"location":"gettingstarted/#Getting-Started","page":"Getting Started","title":"Getting Started","text":"","category":"section"},{"location":"gettingstarted/#Installation","page":"Getting Started","title":"Installation","text":"","category":"section"},{"location":"gettingstarted/","page":"Getting Started","title":"Getting Started","text":"ContextualBandits can be installed using the Julia package manager. From the Julia REPL, type ] to enter the Pkg REPL mode and run","category":"page"},{"location":"gettingstarted/","page":"Getting Started","title":"Getting Started","text":"pkg> add https://github.com/andres-alban/ContextualBandits.jl.git","category":"page"},{"location":"gettingstarted/","page":"Getting Started","title":"Getting Started","text":"note: Note\nThe package is not in the registry but is installed directly from the Github repository.","category":"page"},{"location":"gettingstarted/","page":"Getting Started","title":"Getting Started","text":"Most often, you will also need the following packages:","category":"page"},{"location":"gettingstarted/","page":"Getting Started","title":"Getting Started","text":"pkg> add Distributions, LinearAlgebra","category":"page"},{"location":"gettingstarted/#Basic-Usage","page":"Getting Started","title":"Basic Usage","text":"","category":"section"},{"location":"gettingstarted/","page":"Getting Started","title":"Getting Started","text":"Below is an example of a simulation. simulation_stochastic is the main function that guides the development of policies and other components. We next explain the model behind simulation_stochastic that clarifies the input parameters and outputs.","category":"page"},{"location":"gettingstarted/","page":"Getting Started","title":"Getting Started","text":"using ContextualBandits\nusing Distributions\n\nn = 3\nFX = CovariatesIndependent([Normal(),Normal()])\nm = length(FX)\nT = 10\npolicies = Dict(\"random\" => RandomPolicy(n))\nsample_std = 1.0\nmu = rand(n*m)\noutcome_model = OutcomeLinear(n,m,mu,sample_std)\nreps = 10\n\nresults = simulation_stochastic(reps,FX,n,T,policies,outcome_model)\n\noutput_random = results[\"output\"][\"random\"]\n# vector of length T of cumulative regret\noutput_random[\"cumulregret_on\"]","category":"page"},{"location":"simulation/#Simulation","page":"Simulation","title":"Simulation","text":"","category":"section"},{"location":"simulation/","page":"Simulation","title":"Simulation","text":"simulation_stochastic","category":"page"},{"location":"simulation/#ContextualBandits.simulation_stochastic","page":"Simulation","title":"ContextualBandits.simulation_stochastic","text":"simulation_stochastic(reps, FX, n, T, policies, outcome_model;\n    FXtilde=FX, delay=0, post_reps=0, pilot_samples_per_treatment = 0,\n    Xinterest=zeros(length(FX),0), rng=Random.default_rng(), verbose=false)\n\nSimulate trials and record metrics.\n\nArguments\n\nreps: Number of replications.\nFX: Covariates generator for in-trial covariates (e.g., CovariatesIndependent or CovariatesCopula).\nn: Number of treatments.\nT: Number of patients in the trial (sample size).\npolicies: Dictionary of policies to simulate. The keys are the names of the policies and the values are the policies themselves.\noutcome_model: the model that generates the outcomes (e.g., OutcomeLinear).\n\nOptional arguments\n\nFXtilde: Covariates generator for post-trial covariates (e.g., CovariatesIndependent or CovariatesCopula).\ndelay: Delay in observing outcomes.\npost_reps: Number of replications for post-trial covariates.\npilot_samples_per_treatment: Number of pilot samples per treatment to build a prior distribution before the start of the trial. Default is 0.\nXinterest: Covariates of interest for which specific . Default is an empty matrix.\nrng: Random number generator. Default is Random.default_rng().\nverbose: Print progress of the simulation. Default is false.\n\nReturns\n\nA dictionary with the input arguments and the output of the simulation for each policy.\n\n\n\n\n\n","category":"function"},{"location":"simulation/","page":"Simulation","title":"Simulation","text":"The return value is a dictionary with two keys: \"input\" and \"output\". The \"input\" saves the input parameters to the simulation. The \"output\" contains one key for each policy. For each policy, we output the following metrics:","category":"page"},{"location":"simulation/","page":"Simulation","title":"Simulation","text":"\"regret_on\": online regret\n\"cumulregret_on\": cumulative online regret\n\"PICS_on\": online PICS\n\"cumulPICS_on\": cumulative online PICS \n\"Wfrac_on\": fraction of allocations to each treatment during trial\n\"regret_off\": offline regret\n\"PICS_off\": offline PICS \n\"Wfrac_off\": fraction of allocations to each treatment after implementation","category":"page"},{"location":"simulation/","page":"Simulation","title":"Simulation","text":"Online metrics are recorded for each time t=1:T. All offline metrics are recorded for each time t=0:T. Offline metrics at timet represent the metric in the scenario where the trial would have concluded at time t. For the eight online and offline metrics, the output also provides those metrics for each of the specific covariate values specified in Xinterest, which are saved under the same names with an X at the beginning, for example, \"Xregret_off\" measures the offline regret for subjects that have the covariate values specified in Xinterest.","category":"page"},{"location":"simulation/","page":"Simulation","title":"Simulation","text":"Two additional outputs are provided that are useful for understanding policies that infer the labeling:","category":"page"},{"location":"simulation/","page":"Simulation","title":"Simulation","text":"\"labeling_frac\": which entries of labeling where true when the trial concluded, which after aggregation represents the fraction of replications in which the entries were true.\n\"sum_labeling\": the number of true entries of labeling.","category":"page"},{"location":"simulation/#Parallel-Computing","page":"Simulation","title":"Parallel Computing","text":"","category":"section"},{"location":"simulation/","page":"Simulation","title":"Simulation","text":"Because simulations can be computationally expensive, the simulation_stochastic_parallel is used to distribute the replications evenly among all available workers (see the standard library Distributed Computing page on how to create worker processes).","category":"page"},{"location":"simulation/","page":"Simulation","title":"Simulation","text":"simulation_stochastic_parallel","category":"page"},{"location":"simulation/#ContextualBandits.simulation_stochastic_parallel","page":"Simulation","title":"ContextualBandits.simulation_stochastic_parallel","text":"simulation_stochastic_parallel(reps, FX, n, T, policies, outcome_model;\n    FXtilde=FX, delay=0, post_reps=0, pilot_samples_per_treatment = 0,\n    Xinterest=zeros(length(FX),0), rng=Random.default_rng(), verbose=false)\n\nParallel version of simulation_stochastic. The simulation is distributed among all available workers.\n\nExample\n\nusing Distributed\naddprocs(2)\n@everywhere using ContextualBandits\n# ...\n# generate all the input arguments for the function\n# ...\nresults = simulation_stochastic_parallel(FX, n, T, policies, outcome_model)\n\n\n\n\n\n","category":"function"},{"location":"simulation/","page":"Simulation","title":"Simulation","text":"An effective workflow is to run parallel simulations in a script. At the top of the script, you need to load the package in all workers with @everywhere:","category":"page"},{"location":"simulation/","page":"Simulation","title":"Simulation","text":"# example_parallel.jl\nusing Distributed\n@everywhere using ContextualBandits\n# ...\n# generate all the input arguments for the function\n# ...\nresults = simulation_stochastic_parallel(FX, n, T, policies, outcome_model)","category":"page"},{"location":"simulation/","page":"Simulation","title":"Simulation","text":"Then you run the script with the -p flag indicating the number of workers you want to use or auto to use all available cores (command line interface for Julia):","category":"page"},{"location":"simulation/","page":"Simulation","title":"Simulation","text":"julia -p auto example_parallel.jl","category":"page"},{"location":"simulation/","page":"Simulation","title":"Simulation","text":"If you installed ContextualBandits in a local environment, you also need to activate the environment in all workers using Pkg:","category":"page"},{"location":"simulation/","page":"Simulation","title":"Simulation","text":"# example_parallel.jl\nusing Distributed\n@everywhere using Pkg\n@everywhere Pkg.activate(\".\") # path to the environment\n@everywhere using ContextualBandits\n# ...\n# generate all the input arguments for the function\n# ...\nresults = simulation_stochastic_parallel(FX, n, T, policies, outcome_model)","category":"page"},{"location":"covariates_generation/#Covariates-Generation","page":"Covariates Generation","title":"Covariates Generation","text":"","category":"section"},{"location":"covariates_generation/","page":"Covariates Generation","title":"Covariates Generation","text":"CovariatesIndependent\nCovariatesCopula\nOrdinalDiscrete","category":"page"},{"location":"covariates_generation/#ContextualBandits.CovariatesGeneration.CovariatesIndependent","page":"Covariates Generation","title":"ContextualBandits.CovariatesGeneration.CovariatesIndependent","text":"CovariatesIndependent <: Sampleable{Multivariate,Continuous}\nCovariatesIndependent(marginals, intercept=true, reduce_category=true)\n\nSampleable to randomly generate a vector of covariates using marginal distributions assuming the values are independent of each other.\n\nArguments\n\nmarginals::Array{Distribution{Univariate,S} where S<:ValueSupport,1}: vector of univariate distributions from the Distributions package\nintercept=true: include an intercept term in the vector of covariates\nreduce_category=true: omit the first dummy variable for Categorical covariates\n\nExamples\n\nusing Distributions\nFX = CovariatesIndependent([Categorical([1/3,1/3,1/3]),Normal(0,1)])\nrand(FX)\n\n\n\n\n\n","category":"type"},{"location":"covariates_generation/#ContextualBandits.CovariatesGeneration.CovariatesCopula","page":"Covariates Generation","title":"ContextualBandits.CovariatesGeneration.CovariatesCopula","text":"CovariatesCopula{C} <: Sampleable{Multivariate,Continuous}\nCovariatesCopula(marginals,copula,intercept=true,reduce_category=true)\n\nSampleable to randomly generate a vector of covariates using marginal distributions and copulas from the Copulas.jl package.\n\nCategorical marginal distributions are assumed unordered (nominal) and automatically generated as a set of dummy variables. To use ordered categorical variables, use the OrdinalDiscrete type.\n\nArguments\n\nmarginals::Vector{Distribution{Univariate,S} where S<:ValueSupport}: vector of univariate distributions from the Distributions package\ncopula: copula type from the Copulas package\nintercept=true: include an intercept term in the vector of covariates\nreduce_category=true: omit the first dummy variable for Categorical covariates\n\nExamples\n\nusing Distributions, Copulas\ncopula = GaussianCopula([1 0.2; 0.2 1])\nFX = CovariatesCopula([Categorical([1/3,1/3,1/3]),Normal(0,1)],copula)\nrand(FX)\n\n\n\n\n\n","category":"type"},{"location":"covariates_generation/#ContextualBandits.CovariatesGeneration.OrdinalDiscrete","page":"Covariates Generation","title":"ContextualBandits.CovariatesGeneration.OrdinalDiscrete","text":"struct OrdinalDiscrete{T<:Real,P<:Real,Ts<:AbstractVector{T},Ps<:AbstractVector{P}} <: DiscreteUnivariateDistribution\n\nType to sample from a discrete distribution. Unlike DiscreteNonParametric or Categorical, this type is interpreted as ordinal by CovariatesCopula and CovariatesIndependent.\n\nWARNING: although this type is a Distribution, I have only defined the rand and  quantile functions, which are required for covariate generation.\n\nThe implementation wraps a DiscreteNonParametric variable in a new structure.\n\n\n\n\n\n","category":"type"},{"location":"examples/#Examples","page":"Examples","title":"Examples","text":"","category":"section"},{"location":"examples/#Alban,-Chick,-Zoumpoulis-(2024)","page":"Examples","title":"Alban, Chick, Zoumpoulis (2024)","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"The following example recreates the results of Figure 2a in Alban, Chick, Zoumpoulis (2024). It requires two additional packages to save the data and plot it:","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"pkg> add JLD2, Plots","category":"page"},{"location":"examples/#Example-simulation","page":"Examples","title":"Example simulation","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"The simulation can take several hours because it runs 5000 replications (reps=5000). With ten cores on our machines, this simulation can run in about an hour. However, it may run faster or slower in your machine. We recommend you try it first setting reps=10 or another small number, so you can predict how long it will take to run. You should also adjust the number of cores depending on your computer capacity.","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"using Distributed\naddprocs(10) # adjust the number of cores that will be used for simulation\n@everywhere using Pkg\n@everywhere Pkg.activate(\".\")\n@everywhere using ContextualBandits\nusing Random\nusing Distributions\nusing Statistics\nusing JLD2\nusing LinearAlgebra\n\n# Setting up model\nn = 8 # number of treatments\np = [59,129,184,150]./522 # 4 categories\np_prog = [0.25,0.5,0.25] # low, medium, high\nFX = CovariatesIndependent([Categorical(p),OrdinalDiscrete(p_prog),OrdinalDiscrete(p_prog)])\nFXtilde = CovariatesIndependent([Categorical(p),OrdinalDiscrete(p_prog),OrdinalDiscrete(p_prog)])\nm = length(FX)\nsample_std = 1.0\nlabeling = BitVector(\n         [1,1,1,1,1,0, # prognostic\n          0,0,0,0,0,0, # treatment 1\n          0,0,0,0,0,0, # treatment 2\n          0,0,0,0,0,0, # treatment 3\n          1,0,0,0,0,0, # treatment 4\n          0,1,0,0,0,0, # treatment 5\n          0,1,0,0,0,0, # treatment 6\n          0,1,0,0,0,0, # treatment 7\n          0,1,0,0,0,0, # treatment 8\n          ])\n\n# Setting up nature's distribution\ntheta_nat = zeros(sum(labeling))\nSigma_nat = 4*diagm(ones(sum(labeling)))\n# Positive correlation for the predictive coefficients\nSigma_nat[7:10,7:10] = [4 1 1 0.5;\n                     1 4 0.5 1;\n                     1 0.5 4 1;\n                     0.5 1 1 4]\n\noutcome_model = OutcomeLinearBayes(n, m, theta_nat, Sigma_nat, sample_std, labeling)\ndelay = 0\n\n# Setting up prior\nlabeling0 = labeling\nsigma0 = 2\npsi = log(2)\nD = [\n      0 2 2 3 2 3 3 Inf;\n      2 0 3 2 3 2 Inf 3;\n      2 3 0 2 3 Inf 2 3;\n      3 2 2 0 Inf 3 3 2;\n      2 3 3 Inf 0 2 2 3;\n      3 2 Inf 3 2 0 3 2;\n      3 Inf 2 3 2 3 0 2;\n      Inf 3 3 2 3 2 2 0\n    ]\ntheta0, Sigma0 = default_prior_linear(n, m, sigma0, psi, D, labeling0)\n\n## Random policy\nrandom_policy = RandomPolicyLinear(n, m, theta0, Sigma0, sample_std, labeling0)\n\n## Thompson sampling\nTS_policy = TSPolicyLinear(n, m, theta0, Sigma0, sample_std, labeling0)\n\n## Top-two Thompson sampling\nbeta = 0.5\nmaxiter = 100\nTTTS_policy = TTTSPolicyLinear(n, m, theta0, Sigma0, sample_std, beta, maxiter, labeling0)\n\n## fEVI policy\nfEVI_policy = fEVIDiscrete(n, m, theta0, Sigma0, sample_std, FX, labeling0)\n\n## fEVIon policy\nP = 0\nT = 1000\nfEVIon_policy = fEVIDiscreteOnOff(n, m, theta0, Sigma0, sample_std, FX, P, T, labeling0)\n\n## Biased Coin\np1 = 0.5\npk = vcat([p1], ones(n-1)*(1-p1)/(n-1))\nGweight = [0,0.5,0.5,0]\nbiasedcoin_policy = BiasedCoinPolicyLinear(n, m, theta0, Sigma0, sample_std, FX, labeling0;\n    p=pk, weights = Gweight)\n\n## OCBA\nocba_policy = OCBAPolicyLinear(n, m, theta0, Sigma0, sample_std, FX, labeling0)\n\n## RABC\nGweight = [0.25,0.25,0.25,0.25]\nRABC_policy = RABC_OCBA_PolicyLinear(n, m, theta0, Sigma0, sample_std, FX, labeling0; p=pk, weights=Gweight)\n\n## Greedy\ngreedy_policy = GreedyPolicyLinear(n, m, theta0, Sigma0, sample_std, labeling0)\n\n# policies\npolicies = Dict(\n    \"random\" => random_policy, \"TS\" => TS_policy, \n    \"TTTS\" => TTTS_policy, \"fEVI\" => fEVI_policy, \"fEVIon\" => fEVIon_policy,\n    \"biasedcoin\" => biasedcoin_policy, \"RABC\" => RABC_policy, \"ocba\" => ocba_policy, \n    \"greedy\" => greedy_policy\n)\n\n# Settings for simulation runs\nT = 1000\nreps = 5000 # number of replications\npost_reps = 50\nXinterest = [\n    1 1 1 1;\n    0 1 0 0;\n    0 0 1 0;\n    0 0 0 1;\n    0 0 0 0;\n    0 0 0 0\n]\n\n# run simulation\nrng = Xoshiro(121)\nresults = @time simulation_stochastic_parallel(reps, FX, n, T, policies, outcome_model;\n    FXtilde = FXtilde, delay = delay, post_reps=post_reps, rng=rng, Xinterest=Xinterest)\n\n\n## Save\nsave(\"example.jld2\", results)","category":"page"},{"location":"examples/#Plotting-simulation-data","page":"Examples","title":"Plotting simulation data","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"Once the simulation is finished and the data has been saved, you can reload the data and plot it:","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"using JLD2\nusing Plots\n\n# load data\noutput = load(\"example.jld2\", \"output\")\n\n# policies that will be plotted\npolicy_keys = [\"fEVI\",\"TTTS\",\"RABC\",\"TS\",\"random\",\"fEVIon\"]\n\n# performance metric to plot (regret, cumulregret, pics)\nmetric = \"regret_off\"\n\n# horizon T and sample size\nT = length(output[policy_keys[1]][\"regret_on\"])\n\n# data to plot\nif occursin(\"off\",metric) # offline metric\n    x = 0:T\nelse # online metric\n    x = 1:T\nend\ny = Matrix{Float64}(undef,length(x),length(policy_keys))\nfor i in eachindex(policy_keys)\n    y[:,i] = output[policy_keys[i]][metric][\"mean\"]\nend\n\nplot(x, y, label = policy_keys)","category":"page"},{"location":"model/#Model","page":"Model","title":"Model","text":"","category":"section"},{"location":"model/","page":"Model","title":"Model","text":"There are many \"flavors\" of bandit models and this package is not comprehensive. Therefore, users must understand the underlying model for which this package was designed. The contextual bandit model that we present here was formally introduced in the paper Alban A, Chick SE, Zoumpoulis SI (2024) Learning Personalized Treatment Strategies with Predictive and Prognostic Covariates in Adaptive Clinical Trials.  We introduce some terminology that will be used throughout this documentation. ","category":"page"},{"location":"model/","page":"Model","title":"Model","text":"A trial is a sequence of allocations of T subjects to one of n alternative treatments (arms). Before allocating each subject, we observe a context, which is a vector with m covariates. After each allocation of a subject, we observe the outcome, a noisy scalar that represents how effective the treatment is for the subject (higher values are better). By the end of the trial, we have gathered the following data:","category":"page"},{"location":"model/","page":"Model","title":"Model","text":"W: a T-dimensional vector of integers in 1:n of the treatments allocated to each subject.\nX: a mxT-dimensional matrix where each column is the vector of covariates for a subject. Notice that Julia stores arrays in column-major order.\nY: a T-dimensional vector of scalars with the outcome of each subject.","category":"page"},{"location":"model/#Policy","page":"Model","title":"Policy","text":"","category":"section"},{"location":"model/","page":"Model","title":"Model","text":"A policy makes allocation decisions: it decides to which treatment each subject is allocated. A policy is represented by a subtype of Policy:","category":"page"},{"location":"model/","page":"Model","title":"Model","text":"Policy","category":"page"},{"location":"model/#ContextualBandits.Policy","page":"Model","title":"ContextualBandits.Policy","text":"Policy\n\nSupertype for contextual bandit policies.\n\nThe functions initialize!, state_update!, allocation, and implementation take subtypes of Policy as the first argument. Each subtype of Policy should implement these functions.\n\n\n\n\n\n","category":"type"},{"location":"model/","page":"Model","title":"Model","text":"The main method for any subtype of policy is allocation:","category":"page"},{"location":"model/","page":"Model","title":"Model","text":"ContextualBandits.allocation(::Policy,Xcurrent,W,X,Y)","category":"page"},{"location":"model/#ContextualBandits.allocation-Tuple{Policy, Vararg{Any, 4}}","page":"Model","title":"ContextualBandits.allocation","text":"allocation(policy::Policy,Xcurrent,W,X,Y[, rng])\n\nReturn a treatment to allocate a patient with covariates Xcurrent, given that the trial has observed W, X, and Y. W is the vector of treatments, X is the matrix of covariates, and Y is the vector of outcomes.\n\nThe dimension of Y may be smaller than that of W and X because of delays in outcomes.\n\n\n\n\n\n","category":"method"},{"location":"model/","page":"Model","title":"Model","text":"The allocation depends only on the available data W,X,Y when the allocation is made. However, the policy can also maintain a state. A state can be useful for computational efficiency. For instance, a linear regression model can be updated sequentially rather than retrained for every allocation. To maintain a state, the policy is first initialized and then updated after every observation:","category":"page"},{"location":"model/","page":"Model","title":"Model","text":"ContextualBandits.initialize!(::Policy)\nContextualBandits.state_update!(::Policy,W,X,Y)","category":"page"},{"location":"model/#ContextualBandits.initialize!-Tuple{Policy}","page":"Model","title":"ContextualBandits.initialize!","text":"initialize!(policy::Policy[, W, X, Y])\n\nInitialize the state of a policy before a trial starts. W, X, and Y is data collected in a pilot that can be used to initialize the policy.  W is the vector of treatments, X is the matrix of covariates, and Y is the vector of outcomes.\n\n\n\n\n\n","category":"method"},{"location":"model/#ContextualBandits.state_update!-Tuple{Policy, Any, Any, Any}","page":"Model","title":"ContextualBandits.state_update!","text":"state_update!(policy::Policy,W,X,Y[, rng])\n\nUpdate the state of a policy given the data W, X, and Y. W is the vector of treatments, X is the matrix of covariates, and Y is the vector of outcomes.\n\nFor example, the policy may do Bayesian updating to get posterior parameters.\n\n\n\n\n\n","category":"method"},{"location":"model/","page":"Model","title":"Model","text":"A policy may also define an implementation that determines which treatment a subject arriving post-trial (once the trial has concluded and no more data is being gathered):","category":"page"},{"location":"model/","page":"Model","title":"Model","text":"ContextualBandits.implementation(::Policy,X_Post,W,X,Y)","category":"page"},{"location":"model/#ContextualBandits.implementation-Tuple{Policy, Vararg{Any, 4}}","page":"Model","title":"ContextualBandits.implementation","text":"implementation(policy::Policy,X_post,W,X,Y)\n\nImplement a treatment for covariates X_post given that the trial observed W, X, and Y. W is the vector of treatments, X is the matrix of covariates, and Y is the vector of outcomes.\n\n\n\n\n\n","category":"method"},{"location":"model/","page":"Model","title":"Model","text":"In Policies, we present the policies provided by this package. You can define your own policy by creating a subtype of Policy that defines methods for the above functions.","category":"page"},{"location":"model/#Covariates","page":"Model","title":"Covariates","text":"","category":"section"},{"location":"model/","page":"Model","title":"Model","text":"The covariates X are random draws from a distribution FX, which are independent between subjects. The package provides CovariatesIndependent and CovariatesCopula, which are described in Covariates Generation, to randomly generate covariates. As an example, a covariate that follows a standard normal distribution can be generated as follows:","category":"page"},{"location":"model/","page":"Model","title":"Model","text":"using ContextualBandits\nusing Distributions\n\nFX = CovariatesIndependent([Normal()])\nX = rand(FX)","category":"page"},{"location":"model/#Outcomes","page":"Model","title":"Outcomes","text":"","category":"section"},{"location":"model/","page":"Model","title":"Model","text":"The outcomes of a trial, Y, are generated by an outcome model:","category":"page"},{"location":"model/","page":"Model","title":"Model","text":"OutcomeModel","category":"page"},{"location":"model/#ContextualBandits.OutcomeModel","page":"Model","title":"ContextualBandits.OutcomeModel","text":"OutcomeModel\n\nSupertype for models that determine mean outcomes and noisy outcomes.\n\nThe functions outcome_model_state!, mean_outcome, noisy_outcome, and  noise_outcome take subtypes of OutcomeModel as the first argument. Each subtype should implement these functions.\n\n\n\n\n\n","category":"type"},{"location":"model/","page":"Model","title":"Model","text":"ContextualBandits.mean_outcome\nContextualBandits.noise_outcome\nContextualBandits.noisy_outcome\nContextualBandits.outcome_model_state!","category":"page"},{"location":"model/#ContextualBandits.mean_outcome","page":"Model","title":"ContextualBandits.mean_outcome","text":"mean_outcome(outcome_model::OutcomeModel,W,X)\n\nCompute the mean outcome of treatment W with covariates X.\n\n\n\n\n\n","category":"function"},{"location":"model/#ContextualBandits.noise_outcome","page":"Model","title":"ContextualBandits.noise_outcome","text":"noise_outcome(outcome_model::OutcomeModel,rng::AbstractRNG=Random.default_rng())\n\nGenerate noise object to be passed to noisy_outcome.\n\nIt can generate a normal distribution with zero mean for Gaussian models or vectors of random variables for more complex models.\n\n\n\n\n\n","category":"function"},{"location":"model/#ContextualBandits.noisy_outcome","page":"Model","title":"ContextualBandits.noisy_outcome","text":"noisy_outcome(outcome_model::OutcomeModel,W,X,Z)\n\nCompute noisy outcome of treatment W with covariates X given noise Z.  Z is generated with noise_outcome.\n\nUsually calls mean_outcome and adds zero mean noise Z.\n\n\n\n\n\n","category":"function"},{"location":"model/#ContextualBandits.outcome_model_state!","page":"Model","title":"ContextualBandits.outcome_model_state!","text":"outcome_model_state!(outcome_model::OutcomeModel,rng::AbstractRNG=Random.default_rng())\n\nSet the state of an outcome model. Mainly used to change the state of random instances.\n\n\n\n\n\n","category":"function"},{"location":"model/","page":"Model","title":"Model","text":"In Outcome Models, we present the outcome models provided by this package. You can define your own model by creating a subtype of OutcomeModel that defines methods for the above functions.","category":"page"},{"location":"model/#Delay","page":"Model","title":"Delay","text":"","category":"section"},{"location":"model/","page":"Model","title":"Model","text":"The model allows for fixed delays in observing the outcomes. simulation_stochastic accepts delay as an integer parameter that determines the number of subjects that are allocated before the outcome of a subject is observed. For example if delay=3, then the outcome of subject 1 will be observed only after the allocation of subject 4.","category":"page"},{"location":"model/#Simulation-of-a-Trial","page":"Model","title":"Simulation of a Trial","text":"","category":"section"},{"location":"model/","page":"Model","title":"Model","text":"The model can be understood with the following code snippet that broadly illustrates how the different components enter in a simulation. A simulation will perform this code for many replications, record metrics, and summarize the metrics. See Simulation for more details on the simulation functions.","category":"page"},{"location":"model/","page":"Model","title":"Model","text":"# ...\n# loop over subjects in trial\ninitialize!(policy)\nfor t in 0:(T+delay)\n    # Allocate\n    if 1 <= t <= T\n        # Covariates of the newly arrived subject that has not yet been treated\n        Xcurrent = rand(FX)\n        w = allocation(policy,Xcurrent,view(W,1:(t-1)),view(X,:,1:(t-1)),view(Y,1:(t-delay-1)),rng)\n        @assert w in 1:n \"The policy $(typeof(policy)) made an allocation outside the range 1-$n\"\n        X[:,t] = Xcurrent\n        W[t] = w\n        Y[t] = noisy_outcome(outcome_model,w,view(X,:,t),Z[t])\n    end\n\n    # Available data at time t\n    Wav = view(W,1:min(t,T))\n    Xav = view(X,:,1:min(t,T))\n    Yav = view(Y,1:(t-delay))\n\n    # Update state of policy\n    state_update!(policy,Wav,Xav,Yav,rng)\nend","category":"page"},{"location":"model/#Metrics-and-performance","page":"Model","title":"Metrics and performance","text":"","category":"section"},{"location":"model/","page":"Model","title":"Model","text":"We distinguish between two types of metrics: online and offline. Online performance metrics refer to performance associated with the subjects allocated in the trial, while offline refers to the outcome of subjects that would be allocated to treatment post-trial once an implementation has been chosen. Regret for a subject with covariates x allocated to treatment w is defined as follows:","category":"page"},{"location":"model/","page":"Model","title":"Model","text":"regret = maximum([mean_outcome(outcome_model, wmax, x) - mean_outcome(outcome_model, w, x) for wmax in 1:n])","category":"page"},{"location":"model/","page":"Model","title":"Model","text":"For subjects allocated in the trial, we refer to it as online regret, and for subjects that received the treatment as the post-trial implementation, we refer to it as offline regret. In Alban, Chick, Zoumpoulis (2024) offline regret is referred to as Expected Opportunity Cost (EOC).","category":"page"},{"location":"model/","page":"Model","title":"Model","text":"Another important metric is Probability of Incorrect Selection (PICS):","category":"page"},{"location":"model/","page":"Model","title":"Model","text":"PICS = regret > 0","category":"page"},{"location":"model/","page":"Model","title":"Model","text":"note: Note\nThis package assumes that larger values of the output are better when computing regret and for designing policies.","category":"page"},{"location":"model/","page":"Model","title":"Model","text":"More detail is provided in the output of the Simulation.","category":"page"},{"location":"model/#Linear-Model-with-Labeling","page":"Model","title":"Linear Model with Labeling","text":"","category":"section"},{"location":"model/","page":"Model","title":"Model","text":"A common way to model the the outcomes as a function of the covariates and treatment is through linear model. Most effective policies require a statistical model that learns the coefficients of the linear model. The vast majority of implemented policies in this package use Bayesian Linear Regression to learn those coefficients. We use mu as the true coefficients of the model that are generating the outcomes. theta is the prior/posterior estimate of mu and Sigma is the prior/posterior covariance matrix of the Bayesian linear regression.","category":"page"},{"location":"model/","page":"Model","title":"Model","text":"A reasonable way to implement a linear model is to model each treatment separately. However, we use a more flexible framework of interaction between treatment and covariates with a labeling (see Labeling for details). Thus, the final model is Y = interact(W,n,X,labeling) * mu + sigma * randn(), where sigma^2 is the standard deviation of the noise. Alban, Chick, Zoumpoulis (2024) uses the operator otimes to represent the interact function.","category":"page"},{"location":"model/","page":"Model","title":"Model","text":"interact\ninteract!","category":"page"},{"location":"model/#ContextualBandits.interact","page":"Model","title":"ContextualBandits.interact","text":"interact(w, n, x[, labeling])\n\nInteract a treatment w among n treatment alternatives with covariate vector x (m=length(x)).\n\nWhen labeling is not provided, the function returns a vector WX of length m*n, where all entries are zeros except for WX[(w-1)*m+1:w*m] = x. WX is split into n blocks of size m, where the w-th block is equal to x.\n\nWhen labeling is provided, the function returns a vector WX of length sum(labeling). labeling is a boolean vector of length (n+1)*m that indicates which covariates are predictive and which are prognostic. The first m entries correspond to prognostic terms, the following m entries correspond to the terms predictive with respect to treatment 1, then m entries for treatment 2, and so on.\n\nIf w is a vector, then x must be a matrix such that length(w)==size(x,2), and the output is a matrix with sum(labeling) rows and length(w) columns.\n\nSee also: interact!\n\n#Examples\n\njulia> w = 2;\n       n = 2;\n       x = [1,3,4]\n       interact(w, n, x)\nVector{Float64}:\n 0.0\n 0.0\n 0.0\n 1.0\n 3.0\n 4.0\n\njulia> w = [1,2]\n       n = 2\n       x = [1 1;\n            2 3;\n            5 4]\n       labeling = Bool.([1,1,0,0,0,1,0,1,0])\n       interact(w,n,x,labeling)\n4×2 Matrix{Float64}:\n 1.0  1.0\n 2.0  3.0\n 5.0  0.0\n 0.0  3.0\n\n\n\n\n\n","category":"function"},{"location":"model/#ContextualBandits.interact!","page":"Model","title":"ContextualBandits.interact!","text":"interact!(WX, w, n, x[, labeling])\n\nIn-place version of interact.\n\n\n\n\n\n","category":"function"},{"location":"model/#Labeling","page":"Model","title":"Labeling","text":"","category":"section"},{"location":"model/","page":"Model","title":"Model","text":"A labeling \"labels\" how each covariate interacts with each treatment. It is a boolean vector of size (n+1)*m split into n+1 blocks of m entries. The first m entries represent prognostic covariates, those covariates that have an equal effect on all treatments. By default, all prognostic labels are false, meaning there are no prognostic effects. The remaining n blocks represent the predictive covariates with respect to the corresponding treatment, those covariates that have a treatment-specific effect. By default, all predictive labels are true, meaning each covariates has an effect specific to each treatment, or equivalently, each treatment has a separate model.","category":"page"},{"location":"model/","page":"Model","title":"Model","text":"Generally, the first covariate is an intercept term that is 1 for all subjects. Thus, the first prognostic term represents an intercept term, and the first term for each block of predictive covariates are treatment effects.","category":"page"},{"location":"model/#Bayesian-linear-regression","page":"Model","title":"Bayesian linear regression","text":"","category":"section"},{"location":"model/","page":"Model","title":"Model","text":"We use the following type to learn Bayesian linear regression models. Policies will often use this type","category":"page"},{"location":"model/","page":"Model","title":"Model","text":"BayesLinearRegression","category":"page"},{"location":"model/#ContextualBandits.BayesLinearRegression","page":"Model","title":"ContextualBandits.BayesLinearRegression","text":"BayesLinearRegression(n, m, theta0, Sigma0, sample_std[, labeling])\n\nBayesian linear regression model with n treatments and m covariates.\n\nSee also: ContextualBandits.initialize!, ContextualBandits.state_update!, BayesUpdateNormal, BayesUpdateNormal!\n\n\n\n\n\n","category":"type"},{"location":"model/","page":"Model","title":"Model","text":"This type needs to be first initialized and then data can be passed sequentially (or in batches) to update the posterior distribution.","category":"page"},{"location":"model/","page":"Model","title":"Model","text":"ContextualBandits.initialize!(::BayesLinearRegression)\nContextualBandits.state_update!(::BayesLinearRegression,W,X,Y)","category":"page"},{"location":"model/#ContextualBandits.initialize!-Tuple{BayesLinearRegression}","page":"Model","title":"ContextualBandits.initialize!","text":"initialize!(model::BayesLinearRegression)\n\nReset the posterior mean model.theta_t and covariance matrix model.Sigma_t to the prior  mean theta0 and covariance matrix Sigma0.\n\n\n\n\n\n","category":"method"},{"location":"model/#ContextualBandits.state_update!-Tuple{BayesLinearRegression, Any, Any, Any}","page":"Model","title":"ContextualBandits.state_update!","text":"state_update!(model::BayesLinearRegression, W, X, Y)\n\nUpdate the posterior mean model.theta_t and covariance matrix model.Sigma_t after observing treatments W, covariates X, and outcomes Y.\n\n\n\n\n\n","category":"method"},{"location":"model/","page":"Model","title":"Model","text":"To select a prior, the package provides the following utilities to generate the robust prior of Alban, Chick, Zoumpoulis (2024).","category":"page"},{"location":"model/","page":"Model","title":"Model","text":"default_prior_linear\nrobustify_prior_linear!","category":"page"},{"location":"model/#ContextualBandits.default_prior_linear","page":"Model","title":"ContextualBandits.default_prior_linear","text":"default_prior_linear(n, m, sigma0, psi[, D, labeling])\n\nThe default prior is a method to specify a prior for a linear model that only depends  on a few parameters. It returns the prior mean and covariance matrix for a linear model  with n treatments and m covariates. \n\nThe prior mean is a vector of zeros.\n\nThe prior covariance matrix (Sigma0) has sigma0^2 in all entries of the diagonal. psi is the decay parameter for the covariance between coefficients of the same covariate and D is a symmetric distance matrix between treatments, which is of size (n,n). Off-diagonal elements of the covariance matrix that represent the covariance between two predictive coefficient for the same covariate with respect to two different treatments, say w1 and w2, are given by sigma0^2*exp(-psi*D[w1,w2]).\n\nExample\n\nn = 3\nm = 3\nsigma0 = 1.0\npsi = log(2)\nD = [0 1 2;\n    1 0 1;\n    2 1 0]\nlabeling = BitVector([0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0])\ntheta0, Sigma0 = default_prior_linear(n, m, sigma0, psi, D, labeling)\n\n\n\n\n\n","category":"function"},{"location":"model/#ContextualBandits.robustify_prior_linear!","page":"Model","title":"ContextualBandits.robustify_prior_linear!","text":"robustify_prior_linear!(theta0, Sigma0, n, m[, labeling, z_alpha, c])\n\nRobustify the prior mean vector theta0 and covariance matrix Sigma0 for a linear model with n treatments and m covariates. theta0 elements that are predictive are artificially increased by a factor of z_alpha times the square root of the largest element of Sigma0. Sigma0 is multiplied by scalar c.\n\nBy default z_alpha=2 and c=4.\n\n\n\n\n\n","category":"function"},{"location":"model/#Additional-utilities","page":"Model","title":"Additional utilities","text":"","category":"section"},{"location":"model/","page":"Model","title":"Model","text":"BayesUpdateNormal\nBayesUpdateNormal!","category":"page"},{"location":"model/#ContextualBandits.BayesUpdateNormal","page":"Model","title":"ContextualBandits.BayesUpdateNormal","text":"BayesUpdateNormal(theta,Sigma,X,y,sample_std)\n\nUpdate Bayesian hyperparameters theta (mean vector) and Sigma (covariance matrix) of a linear regression model with regressor matrix X, outputs y, and sampling standard deviation sample_std.\n\nReturn a copy of the updated theta and Sigma.\n\nX can be a vector of regressors or a matrix of regressors, where each column is a vector of regressors. In the latter case, y and sample_std can be vectors of the same length as the number of columns of X.\n\nSee also: BayesUpdateNormal!\n\n\n\n\n\n","category":"function"},{"location":"model/#ContextualBandits.BayesUpdateNormal!","page":"Model","title":"ContextualBandits.BayesUpdateNormal!","text":"BayesUpdateNormal!(theta,Sigma,X,y,sample_std)\n\nIn-place version of BayesUpdateNormal\n\n\n\n\n\n","category":"function"},{"location":"outcome_models/#Outcome-Models","page":"Outcome Models","title":"Outcome Models","text":"","category":"section"},{"location":"outcome_models/","page":"Outcome Models","title":"Outcome Models","text":"In Model, we introduced the OutcomeModel abstract type. Here, we provide subtypes for linear outcome model.","category":"page"},{"location":"outcome_models/","page":"Outcome Models","title":"Outcome Models","text":"OutcomeLinear\nOutcomeLinearBayes","category":"page"},{"location":"outcome_models/#ContextualBandits.OutcomeLinear","page":"Outcome Models","title":"ContextualBandits.OutcomeLinear","text":"OutcomeLinear <: OutcomeModel\nOutcomeLinear(n, m, mu, sample_std[, labeling])\n\nLinear outcome model with fixed coefficients mu. n is the number of treatments, m is the number of covariates, including the intercept term. The first m coefficients represent prognostic effects (effects independent of the treatment) for each of the m covariates. The following m coefficients represent the predictive effects of treatment 1 (interaction between treatment and covariates). In total, there are at most (n+1)*m coefficients. labeling is a boolean vector of length (n+1)*m indicationg active coefficients. If any coefficient is knwon to be zero (inactive), the corresponding entry of labeling should be false. The length of mu should be equal to the number of active coefficients=sum(labeling). By default, only predictive coefficients are active.\n\nOutcomes are observed with white noise around the mean with sample standard deviation sample_std.\n\n\n\n\n\n","category":"type"},{"location":"outcome_models/#ContextualBandits.OutcomeLinearBayes","page":"Outcome Models","title":"ContextualBandits.OutcomeLinearBayes","text":"OutcomeLinearBayes <: OutcomeModel\nOutcomeLinearBayes(n, m, theta0, Sigma0, sample_std[, labeling])\n\nLinear outcome model with coefficients randomly drawn from a normal prior distribution with mean vector theta0 and covariance matrix Sigma0. n is the number of treatments, m is the number of covariates, including the intercept term. The first m coefficients represent prognostic effects (effects independent of the treatment) for each of the m covariates. The following m coefficients represent the predictive effects of treatment 1 (interaction between treatment and covariates). In total, there are at most (n+1)*m coefficients. labeling is a boolean vector of length (n+1)*m indicationg active coefficients. If any coefficient is knwon to be zero (inactive), the corresponding entry of labeling should be false. The length of theta0 and the dimensions of Sigma0 should be equal to the number of active coefficients=sum(labeling). By default, only predictive coefficients are active.\n\nOutcomes are observed with white noise around the mean with sample standard deviation sample_std.\n\n\n\n\n\n","category":"type"},{"location":"#Introduction","page":"Introduction","title":"Introduction","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"ContextualBandits.jl is a Julia package that implements contextual bandit policies and functionality to estimate regret and other metrics through simulation. It was originally developed to simulate the contextual bandit policies in the paper Alban A, Chick SE, Zoumpoulis SI (2024) Learning Personalized Treatment Strategies with Predictive and Prognostic Covariates in Adaptive Clinical Trials. Although the functionality of the package is broader than that of the paper, ContextualBandits.jl is heavily influenced by the paper's model, which focuses on rewards/signals that are linear function of the contextual information plus some noise and policies that learn a Bayesian linear regression model.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"The Getting Started page shows how to install the package and the easiest way to start using it. However, we recommend that you read the Model page to understand some important concepts. Additional pages complement the Model page.","category":"page"},{"location":"#If-you-are-new-to-Julia","page":"Introduction","title":"If you are new to Julia","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"To install Julia follow the instructions at https://julialang.org/downloads. The Julia manual is a valuable resource, but you can start with one of the tutorials listed at https://julialang.org/learning/tutorials/, such as From Zero to Julia. Understanding the package manager, which comes with the Julia installation, will help you understand how easy it is to install this package for your own use.","category":"page"},{"location":"policies/#Policies","page":"Policies","title":"Policies","text":"","category":"section"},{"location":"policies/","page":"Policies","title":"Policies","text":"In Model, we introduced the Policy abstract type. Here, we first introduced PolicyLinear that serves as the supertype for the policies with a linear model. Then, we introduce the concrete policies that are defined by the package. More detail about the policies defined here is provided in Alban, Chick, Zoumpoulis (2024).","category":"page"},{"location":"policies/#Linear-Policies","page":"Policies","title":"Linear Policies","text":"","category":"section"},{"location":"policies/","page":"Policies","title":"Policies","text":"PolicyLinear","category":"page"},{"location":"policies/#ContextualBandits.PolicyLinear","page":"Policies","title":"ContextualBandits.PolicyLinear","text":"PolicyLinear <: Policy\n\nAbstract supertype that updates using the model with a labeling and implements the treatments strategy that maximizes expected outcomes. It does not provide an allocation policy, which should be defined for each subtype.\n\nAll subtypes must include a model::BayesLinearRegression field. initialize! and state_update! methods are defined to maintain the state. An implementation method is defined to implement the treatment with the largest expected value. An allocation method must be defined by the subtypes.\n\n\n\n\n\n","category":"type"},{"location":"policies/","page":"Policies","title":"Policies","text":"All instances of PolicyLinear use Bayesian linear regression and thus require a prior distribution that can be specified using default_prior_linear and robustify_prior_linear!.","category":"page"},{"location":"policies/#Expected-Value-of-Information-(EVI)","page":"Policies","title":"Expected Value of Information (EVI)","text":"","category":"section"},{"location":"policies/","page":"Policies","title":"Policies","text":"fEVI_MC_PolicyLinear","category":"page"},{"location":"policies/#ContextualBandits.fEVI_MC_PolicyLinear","page":"Policies","title":"ContextualBandits.fEVI_MC_PolicyLinear","text":"fEVI_MC_PolicyLinear <: PolicyLinear\nfEVI_MC_PolicyLinear(n, m, theta0, Sigma0, sample_std, FXtilde, etaon, etaoff, labeling=vcat(falses(m),trues(n*m)))\n\nAllocate treatment using the fEVI-MC allocation policy and update based on the linear model with labeling to make an implementation.\n\n\n\n\n\n","category":"type"},{"location":"policies/","page":"Policies","title":"Policies","text":"fEVIDiscrete\nfEVIDiscreteOnOff","category":"page"},{"location":"policies/#ContextualBandits.fEVIDiscrete","page":"Policies","title":"ContextualBandits.fEVIDiscrete","text":"fEVIDiscrete <: PolicyLinearDiscrete\nfEVIDiscrete(n, m, theta0, Sigma0, sample_std, FX, labeling=vcat(falses(m),trues(n*m)))\n\nAllocate treatment using the fEVI allocation policy and update based on the linear model with labeling to make an implementation.\n\n\n\n\n\n","category":"type"},{"location":"policies/#ContextualBandits.fEVIDiscreteOnOff","page":"Policies","title":"ContextualBandits.fEVIDiscreteOnOff","text":"fEVIDiscreteOnOff <: PolicyLinearDiscrete\nfEVIDiscreteOnOff(n, m, theta0, Sigma0, sample_std, FX, P, T, labeling=vcat(falses(m),trues(n*m)))\n\nAllocate treatment using the fEVI allocation policy (with online and offline rewards) and update based on linear model with labeling to make an implementation.\n\n\n\n\n\n","category":"type"},{"location":"policies/#Thompson-sampling","page":"Policies","title":"Thompson sampling","text":"","category":"section"},{"location":"policies/","page":"Policies","title":"Policies","text":"TSPolicyLinear\nTTTSPolicyLinear","category":"page"},{"location":"policies/#ContextualBandits.TSPolicyLinear","page":"Policies","title":"ContextualBandits.TSPolicyLinear","text":"TSPolicyLinear <: PolicyLinear\nTSPolicyLinear(n, m, theta0, Sigma0, sample_std[, labeling])\n\nAllocate treatment using Thompson Sampling and update based on the linear model with labeling to make an implementation.\n\n\n\n\n\n","category":"type"},{"location":"policies/#ContextualBandits.TTTSPolicyLinear","page":"Policies","title":"ContextualBandits.TTTSPolicyLinear","text":"TTTSPolicyLinear <: PolicyLinear\nTTTSPolicyLinear(n, m, theta0, Sigma0, sample_std, beta, maxiter[, labeling])\n\nAllocate treatment using Top-Two Thompson Sampling and update based on the linear model with labeling to make an implementation.\n\nRusso D (2020) Simple Bayesian algorithms for best arm identification. Operations Research 68(6)\n\n\n\n\n\n","category":"type"},{"location":"policies/#Optimal-Computing-Budget-Allocation-(OCBA)","page":"Policies","title":"Optimal Computing Budget Allocation (OCBA)","text":"","category":"section"},{"location":"policies/","page":"Policies","title":"Policies","text":"OCBAPolicyLinear","category":"page"},{"location":"policies/#ContextualBandits.OCBAPolicyLinear","page":"Policies","title":"ContextualBandits.OCBAPolicyLinear","text":"OCBAPolicyLinear <: PolicyLinear\nOCBAPolicyLinear(n, m, theta0, Sigma0, sample_std, predictive, labeling=vcat(falses(m),trues(n*m)))\nOCBAPolicyLinear(n, m, theta0, Sigma0, sample_std, FX::Union{CovariatesCopula, CovariatesIndependent}, labeling=vcat(falses(m),trues(n*m)))\n\nAllocate treatment using the OCBA algorithm and update based on the linear model with labeling to make an implementation.\n\npredictive is a vector of integers that specifies the covariates that define predictive groups, i.e., patients in the same predictive group have the same covariate values for the covariates specified in predictive. Instead of predictive, you can pass FX, which is a CovariatesCopula or CovariatesIndependent object, and the predictive groups will be automatically determined based on the labeling.\n\nNOTE: the covariates specified in predictive should be discrete. If it is not discrete, the algorithm will run but the results may not be meaningful.\n\n\n\n\n\n","category":"type"},{"location":"policies/#Biased-coin","page":"Policies","title":"Biased coin","text":"","category":"section"},{"location":"policies/","page":"Policies","title":"Policies","text":"BiasedCoinPolicyLinear\nRABC_OCBA_PolicyLinear","category":"page"},{"location":"policies/#ContextualBandits.BiasedCoinPolicyLinear","page":"Policies","title":"ContextualBandits.BiasedCoinPolicyLinear","text":"BiasedCoinPolicyLinear <: PolicyLinear\nBiasedCoinPolicyLinear(n, m, theta0, Sigma0, sample_std, predictive, prognostic, labeling=vcat(falses(m),trues(n*m)); p=vcat(0.5, 0.5*ones(n-1)/(n-1)), weights=vcat(0.0,ones(length(prognostic))/length(prognostic),0.0), target_fraction=ones(n)/n)\nBiasedCoinPolicyLinear(n, m, theta0, Sigma0, sample_std, FX::Union{CovariatesCopula,CovariatesIndependent}, labeling=vcat(falses(m),trues(n*m)); p=vcat(0.5, 0.5*ones(n-1)/(n-1)), weights=nothing, target_fraction=ones(n)/n)\n\nA policy that allocates treatments according to a biased coin design and implements using a linear model with a labeling.\n\nSee Zhao, W., Ma, W., Wang, F., & Hu, F. (2022). Incorporating covariates information in adaptive clinical trials for precision medicine. Pharmaceutical Statistics, 21(1), 176-195. for the measure of the score. However, this policy allocates using a fixed target_fraction, instead of a response-adaptive allocation. See RABC_OCBA_PolicyLinear for a response-adaptive version of this policy.\n\n\n\n\n\n","category":"type"},{"location":"policies/#ContextualBandits.RABC_OCBA_PolicyLinear","page":"Policies","title":"ContextualBandits.RABC_OCBA_PolicyLinear","text":"RABC_OCBA_PolicyLinear <: PolicyLinear\nRABC_OCBA_PolicyLinear(n, m, theta0, Sigma0, sample_std, predictive, prognostic, labeling=vcat(falses(m),trues(n*m)); p=vcat(0.5, 0.5*ones(n-1)/(n-1)), weights=vcat(0.0,ones(length(prognostic))/length(prognostic),0.0))\nRABC_OCBA_PolicyLinear(n, m, theta0, Sigma0, sample_std, FX::Union{CovariatesCopula,CovariatesIndependent}, labeling=vcat(falses(m),trues(n*m)); p=vcat(0.5, 0.5*ones(n-1)/(n-1)), weights=nothing)\n\nReasponse-Adaptive Biased Coin (RABC) using OCBA for the target fraction. A policy that allocates treatments according to a response-adative biased coin design and implements using a linear model with a labeling. The response-adaptive version target fraction is updated using the OCBA method.\n\nSee Zhao, W., Ma, W., Wang, F., & Hu, F. (2022). Incorporating covariates information in adaptive clinical trials for precision medicine. Pharmaceutical Statistics, 21(1), 176-195. for the measure of the score. \n\nSee BiasedCoinPolicyLinear for a non-response-adaptive version of this policy.\n\nSee OCBAPolicyLinear for the OCBA policy without biased coin.\n\n\n\n\n\n","category":"type"},{"location":"policies/#Policy-Modifiers","page":"Policies","title":"Policy Modifiers","text":"","category":"section"},{"location":"policies/#Infer-labeling","page":"Policies","title":"Infer labeling","text":"","category":"section"},{"location":"policies/","page":"Policies","title":"Policies","text":"InferLabelingPolicy","category":"page"},{"location":"policies/#ContextualBandits.InferLabelingPolicy","page":"Policies","title":"ContextualBandits.InferLabelingPolicy","text":"InferLabelingPolicy{T<:PolicyLinear, S<:LabelingSelector} <: Policy\nInferLabelingPolicy(subpolicy, selector, schedule, [labeling0; sigma0, psi, D, z_alpha, c])\n\nCreate a policy that modifies subpolicy by using a labeling selector to infer the labeling at a specified schedule.\n\n\n\n\n\n","category":"type"},{"location":"policies/","page":"Policies","title":"Policies","text":"The InferLabelingPolicy requires a LabelingSelector:","category":"page"},{"location":"policies/","page":"Policies","title":"Policies","text":"LabelingSelector\nContextualBandits.initialize!(::LabelingSelector)\nContextualBandits.labeling_selection","category":"page"},{"location":"policies/#ContextualBandits.LabelingSelector","page":"Policies","title":"ContextualBandits.LabelingSelector","text":"LabelingSelector\n\nSupertype for labeling selectors. Subtypes should implement the  labeling_selection and initialize! functions.\n\n\n\n\n\n","category":"type"},{"location":"policies/#ContextualBandits.initialize!-Tuple{LabelingSelector}","page":"Policies","title":"ContextualBandits.initialize!","text":"initialize!(selection::LabelingSelector)\n\nInitialize the labeling selector. This function is called before the start of the trial.\n\n\n\n\n\n","category":"method"},{"location":"policies/#ContextualBandits.labeling_selection","page":"Policies","title":"ContextualBandits.labeling_selection","text":"labeling_selection(selection::LabelingSelector, W, X, Y[, rng])\n\nSelect a labeling based on the vector of treatments W, covariates matrix X, and vector of outcomes Y.\n\n\n\n\n\n","category":"function"},{"location":"policies/","page":"Policies","title":"Policies","text":"The following LabelingSelector using Lasso was described in Alban, Chick, Zoumpoulis (2024):","category":"page"},{"location":"policies/","page":"Policies","title":"Policies","text":"LassoCVLabelingSelector","category":"page"},{"location":"policies/#ContextualBandits.LassoCVLabelingSelector","page":"Policies","title":"ContextualBandits.LassoCVLabelingSelector","text":"LassoCVLabelingSelector <: LabelingSelector\nLassoCVLabelingSelector(n,m,factor=0.0[, labeling_base])\n\nLabeling selector that uses Lasso with cross validation to select a labeling. The factor parameter is used to select the best model from cross validation: factor == 0 selects the model with the lowest mean loss; factor > 0 selects the sparsest model that is within factor standard erros of the model with lowest mean loss (factor=1 is the commonly used 1se); factor < 0 selects the model with the most non-zero coefficients that is within abs(factor) standard errors of the model with lowest mean loss; labeling_base is the initial labeling.\n\n\n\n\n\n","category":"type"},{"location":"policies/#Discretize-policy","page":"Policies","title":"Discretize policy","text":"","category":"section"},{"location":"policies/","page":"Policies","title":"Policies","text":"DiscretizePolicy","category":"page"},{"location":"policies/#ContextualBandits.DiscretizePolicy","page":"Policies","title":"ContextualBandits.DiscretizePolicy","text":"DiscretizePolicy{T<:Policy} <: Policy\nDiscretizePolicy(subpolicy::T, FX::Union{CovariatesIndependent,CovariatesCopula}, breakpoints) where {T<:Policy}\n\nModify subpolicy by discretizing the covariates in FX before passing them to subpolicy.`\n\n\n\n\n\n","category":"type"}]
}
